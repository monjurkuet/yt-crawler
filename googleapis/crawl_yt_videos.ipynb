{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJmWShUfb94hh9uelhU0EA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monjurkuet/yt-crawler/blob/main/crawl_yt_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac34905a"
      },
      "source": [
        "# Automated YouTube Data Ingestion Pipeline Setup & Execution\n",
        "\n",
        "This notebook demonstrates how to automatically set up the environment in Google Colab, clone the GitHub repository containing the modularized data ingestion code, install dependencies, manage credentials, and run the data ingestion process. This is designed for a fresh Colab environment.\n",
        "\n",
        "**Before Running:**\n",
        "1.  **Ensure you have the GitHub repository:** `https://github.com/monjurkuet/yt-crawler.git` contains the `googleapis` directory with the Python modules.\n",
        "2.  **Configure Colab Userdata Secrets:** Make sure the following secrets are set in your Colab environment (under the ðŸ”‘ icon on the left panel):\n",
        "    *   `API_KEY` (Your YouTube Data API key)\n",
        "    *   `SSH_HOST` (Your SSH server host address)\n",
        "    *   `DATABASE_NAME` (Your MySQL database name)\n",
        "    *   `DATABASE_PASSWORD`\n",
        "3.  **Ensure Google Drive Files are Present:**\n",
        "    *   Your SSH private key file (e.g., `databasemart`) in `/content/drive/MyDrive/cloudaccess/`\n",
        "    *   Your `videoids.txt` file in `/content/drive/MyDrive/cloudaccess/` (one video ID per line)\n",
        "Once these prerequisites are met, simply run all cells in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a69d5ad",
        "collapsed": true
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "import warnings\n",
        "\n",
        "# --- Configuration Variables (Adjust as needed) ---\n",
        "REPO_URL = 'https://github.com/monjurkuet/yt-crawler.git'\n",
        "REPO_NAME = 'yt-crawler'\n",
        "LOCAL_REPO_PATH = os.path.join('/content', REPO_NAME)\n",
        "MODULES_DIR = os.path.join(LOCAL_REPO_PATH, 'googleapis')\n",
        "\n",
        "SSH_PRIVATEKEY_DRIVE_PATH = '/content/drive/MyDrive/cloudaccess/databasemart'\n",
        "VIDEO_IDS_DRIVE_PATH = '/content/drive/MyDrive/cloudaccess/videoids.txt'\n",
        "\n",
        "# --- 0. Suppress Paramiko UserWarning ---\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='paramiko')\n",
        "\n",
        "print(\"--- Starting Automated Colab Setup and Execution ---\")\n",
        "\n",
        "# --- 1. Install Git (if not already present) ---\n",
        "print(\"1. Checking for Git installation...\")\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install -y git > /dev/null\n",
        "print(\"   Git installation checked/completed.\")\n",
        "\n",
        "# --- 2. Clone the GitHub Repository ---\n",
        "print(f\"2. Cloning GitHub repository: {REPO_URL} into {LOCAL_REPO_PATH}...\")\n",
        "if not os.path.exists(LOCAL_REPO_PATH):\n",
        "    !git clone {REPO_URL} {LOCAL_REPO_PATH}\n",
        "    print(\"   Repository cloned.\")\n",
        "else:\n",
        "    print(\"   Repository already cloned. Skipping.\")\n",
        "    # Optionally, pull latest changes\n",
        "    # %cd {LOCAL_REPO_PATH}\n",
        "    # !git pull\n",
        "    # %cd /\n",
        "\n",
        "# --- 3. Change directory to the cloned repository for pip install ---\n",
        "# This is important for pip to find requirements.txt correctly\n",
        "os.chdir(LOCAL_REPO_PATH)\n",
        "print(f\"3. Changed current working directory to: {os.getcwd()}\")\n",
        "\n",
        "# --- 4. Install Dependencies from requirements.txt ---\n",
        "print(f\"4. Installing Python packages from {MODULES_DIR}/requirements.txt...\")\n",
        "!pip install -r {MODULES_DIR}/requirements.txt\n",
        "print(\"   Dependencies installed.\")\n",
        "\n",
        "# --- 5. Mount Google Drive and Set Permissions ---\n",
        "print(\"5. Mounting Google Drive...\")\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"   Google Drive mounted.\")\n",
        "else:\n",
        "    print(\"   Google Drive already mounted.\")\n",
        "\n",
        "print(f\"   Setting permissions for SSH private key: {SSH_PRIVATEKEY_DRIVE_PATH}...\")\n",
        "if os.path.exists(SSH_PRIVATEKEY_DRIVE_PATH):\n",
        "    !chmod 600 {SSH_PRIVATEKEY_DRIVE_PATH}\n",
        "    print(\"   SSH private key permissions set.\")\n",
        "else:\n",
        "    print(f\"   WARNING: SSH private key not found at {SSH_PRIVATEKEY_DRIVE_PATH}. Data ingestion might fail.\")\n",
        "\n",
        "# --- 6. Export Colab Userdata as Environment Variables ---\n",
        "print(\"6. Setting environment variables from Colab userdata...\")\n",
        "# These variables are read by config_manager.py, prioritizing os.environ\n",
        "os.environ['API_KEY'] = userdata.get('API_KEY')\n",
        "os.environ['SSH_HOST'] = userdata.get('SSH_HOST')\n",
        "os.environ['SSH_USERNAME'] = 'administrator' # Fixed username\n",
        "os.environ['SSH_PRIVATEKEY_PATH'] = SSH_PRIVATEKEY_DRIVE_PATH # Use the path confirmed above\n",
        "os.environ['DATABASE_NAME'] = userdata.get('DATABASE_NAME')\n",
        "os.environ['DATABASE_PASSWORD'] = userdata.get('DATABASE_PASSWORD')\n",
        "\n",
        "# Add other fixed parameters that config_manager.py might expect as environment variables\n",
        "os.environ['LOCAL_PORT'] = '3307'\n",
        "os.environ['REMOTE_MYSQL_HOST'] = '127.0.0.1'\n",
        "os.environ['REMOTE_MYSQL_PORT'] = '3306'\n",
        "\n",
        "print(\"   Environment variables set.\")\n",
        "\n",
        "# --- 7. Add googleapis directory to Python path ---\n",
        "print(f\"7. Adding {MODULES_DIR} to Python's system path...\")\n",
        "if MODULES_DIR not in sys.path:\n",
        "    sys.path.insert(0, MODULES_DIR)\n",
        "    print(f\"   Added {MODULES_DIR} to sys.path.\")\n",
        "else:\n",
        "    print(f\"   {MODULES_DIR} already in sys.path. Skipping.\")\n",
        "\n",
        "# --- 8. Execute main.py from the cloned repository ---\n",
        "print(\"\\n--- 8. Starting data ingestion process ---\")\n",
        "\n",
        "try:\n",
        "    from main import DataIngestor # Import from the googleapis directory due to sys.path adjustment\n",
        "    ingestor = DataIngestor()\n",
        "    ingestor.ingest_data()\n",
        "    print(\"\\n--- Data ingestion process finished successfully. ---\")\n",
        "except ModuleNotFoundError as e:\n",
        "    print(f\"\\nERROR: Could not import DataIngestor. Check sys.path and module names. Details: {e}\")\n",
        "    print(\"Please ensure 'googleapis' directory contains main.py and is correctly added to sys.path.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nCRITICAL ERROR during data ingestion: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"--- Automated Colab Setup and Execution Complete ---\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}